{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv tavily-python langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iYEdANAAhwk",
        "outputId": "b35e89be-ac98-4492-f08b-c07fccab0d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.54-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from tavily-python) (0.8.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from tavily-python) (0.27.2)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.3.19)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.42-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.11)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.9.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (2.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.23.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->tavily-python) (1.2.2)\n",
            "Downloading langgraph-0.2.54-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.8-py3-none-any.whl (35 kB)\n",
            "Downloading langgraph_sdk-0.1.42-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: langgraph-sdk, langgraph-checkpoint, langgraph\n",
            "Successfully installed langgraph-0.2.54 langgraph-checkpoint-2.0.8 langgraph-sdk-0.1.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03yk5NdP8bQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2853f2d-5aa2-4a3b-ad32-3a5312440c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-b9e6246a5afb>:38: LangGraphDeprecationWarning: ToolExecutor is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
            "  tool_executor = ToolExecutor(tools)\n",
            "<ipython-input-11-b9e6246a5afb>:52: LangGraphDeprecationWarning: ToolInvocation is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
            "  return {\"tool_call\": ToolInvocation(tool=\"web_search\", tool_input={\"query\": input_text})}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Tell me about LangChain.\n",
            "Result: [{'title': \"How to Use LangChain to Build With LLMs - A Beginner's Guide\", 'link': 'https://www.freecodecamp.org/news/beginners-guide-to-langchain/', 'snippet': 'LangChain is a Python library that simplifies working with large language models (LLMs) like OpenAI, Anthropic, and Google. Learn how to use LangChain to create chatbots, generate text, and stream output with examples and tutorials.'}, {'title': 'Introduction to LangChain - GeeksforGeeks', 'link': 'https://www.geeksforgeeks.org/introduction-to-langchain/', 'snippet': 'Data Structures and Algorithms\\nML & Data Science\\nWeb Development\\nLanguages\\nInterview Corner\\nCS Subjects\\nJobs\\nPractice\\nContests\\nIntroduction to Langchain\\nLangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). LangChain follows a general pipeline where a user asks a question to the language model where the vector representation of the question is used to do a similarity search in the vector database and the relevant information is fetched from the vector database and the response is later fed to the language model. LangChain Key Concepts:\\nThe main properties of LangChain Framework are :\\nSetting up the environment\\nInstallation of langchain is very simple and similar as you install other libraries using the pip command.\\n Next, we create a .env file and store our API key in it as follows:\\nPython\\nNow, I am creating a new file named ‘lang.py’ where I will be using the LangChain framework to generate responses. We start by importing long-chain and initializing an LLM as follows:\\nPython\\nWe are initializing it with a high temperature which means that the results will be random and less accurate.'}, {'title': 'What Is LangChain and How to Use It: A Guide - TechTarget', 'link': 'https://www.techtarget.com/searchEnterpriseAI/definition/LangChain', 'snippet': \"Everything you need to know\\nWhat are the features of LangChain?\\nLangChain is made up of the following modules that ensure the multiple components needed to make an effective NLP app can run smoothly:\\nWhat are the integrations of LangChain?\\nLangChain typically builds applications using integrations with LLM providers and external sources where data can be found and stored. What is synthetic data?\\nExamples and use cases for LangChain\\nThe LLM-based applications LangChain is capable of building can be applied to multiple advanced use cases within various industries and vertical markets, such as the following:\\nReaping the benefits of NLP is a key of why LangChain is important. As the airline giant moves more of its data workloads to the cloud, tools from Intel's Granulate are making platforms such as ...\\nThe vendor's new platform, now in beta testing, combines its existing lakehouse with AI to better enable users to manage and ...\\n The following steps are required to use this:\\nIn this scenario, the language model would be expected to take the two input variables -- the adjective and the content -- and produce a fascinating fact about zebras as its output.\\n The goal of LangChain is to link powerful LLMs, such as OpenAI's GPT-3.5 and GPT-4, to an array of external data sources to create and reap the benefits of natural language processing (NLP) applications.\\n\"}, {'title': 'Introduction | ️ LangChain', 'link': 'https://python.langchain.com/docs/introduction/', 'snippet': \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\"}, {'title': 'About - LangChain', 'link': 'https://www.langchain.com/about', 'snippet': 'Ready to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. Announcing the General Availability of LangSmith\\nToday, we’re thrilled to announce the general availability of LangSmith — our solution for LLM application development, monitoring, and testing.\\n We build products that enable developers to go from an idea to working code in an afternoon and in the hands of users in days or weeks. The biggest developer community in \\xa0GenAI\\nLearn alongside the 100K+ practitioners\\nwho are pushing the industry forward.\\n And we built LangSmith to support all stages of the AI engineering lifecycle, to get applications into production faster.\\n'}]\n"
          ]
        }
      ],
      "source": [
        "import operator\n",
        "import os\n",
        "from datetime import datetime\n",
        "from typing import Annotated, TypedDict, Union\n",
        "from dotenv import load_dotenv\n",
        "from tavily import TavilyClient\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.prebuilt import ToolExecutor, ToolInvocation\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "TAVILY_API_KEY=\"\"\n",
        "# Initialize Tavily client\n",
        "tavily = TavilyClient(TAVILY_API_KEY)\n",
        "\n",
        "@tool\n",
        "def web_search(query: str):\n",
        "    \"\"\"Perform a web search for the given query using Tavily.\"\"\"\n",
        "    try:\n",
        "        # Use Tavily's search method\n",
        "        search_result = tavily.search(query=query, max_results=5)\n",
        "\n",
        "        # Extract and format the results\n",
        "        return [\n",
        "            {\n",
        "                \"title\": result.get(\"title\", \"No Title\"),\n",
        "                \"link\": result.get(\"url\", \"\"),\n",
        "                \"snippet\": result.get(\"content\", \"No content\")\n",
        "            }\n",
        "            for result in search_result.get(\"results\", [])\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        return f\"Error during Tavily search: {str(e)}\"\n",
        "\n",
        "# Prepare tools\n",
        "tools = [web_search]\n",
        "tool_executor = ToolExecutor(tools)\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    input: str\n",
        "    intermediate_steps: Annotated[list[tuple], operator.add]\n",
        "    tool_call: Union[ToolInvocation, None]\n",
        "\n",
        "def execute_tool(state: AgentState):\n",
        "    tool_call = state['tool_call']\n",
        "    response = tool_executor.invoke(tool_call)\n",
        "    return {\"intermediate_steps\": [(tool_call, response)]}\n",
        "\n",
        "def determine_tool(state: AgentState):\n",
        "    input_text = state['input']\n",
        "    return {\"tool_call\": ToolInvocation(tool=\"web_search\", tool_input={\"query\": input_text})}\n",
        "\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"select_tool\", determine_tool)\n",
        "workflow.add_node(\"execute_tool\", execute_tool)\n",
        "workflow.set_entry_point(\"select_tool\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"select_tool\",\n",
        "    lambda state: \"execute_tool\" if state['tool_call'] else END,\n",
        "    {\n",
        "        \"execute_tool\": \"execute_tool\",\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "workflow.add_edge(\"execute_tool\", END)\n",
        "\n",
        "\n",
        "\n",
        "input_text_search = \"Tell me about LangChain.\"\n",
        "inputs_search = {\"input\": input_text_search, \"intermediate_steps\": []}\n",
        "app_search = workflow.compile()\n",
        "result_search = app_search.invoke(inputs_search)\n",
        "print(\"\\nInput:\", input_text_search)\n",
        "print(\"Result:\", result_search['intermediate_steps'][0][1])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTJ2BPJvAfmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zhzbyONKAZZ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}